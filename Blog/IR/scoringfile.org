# -*- mode: org -*-
# Last modified: <2012-04-26 12:02:54 Thursday by richard>
#+STARTUP: showall
#+TITLE:   Scoring, term weighting and the vector space model

* Parametric and Zone Indexes.
** Jargons:
   1. metadata, we mean specific forms of data about a document, such
      as its author(s), title and date of publication.
   2. fields, included by metadata,
      such as the date of creation and the format of the document, as
      well the author and possibly the title of the document.
   3. parametric metrix, There is one parametric index for each field
      (say, date of creation); it allows us to select only the
      documents matching a date specified in the query.
   4. Zones are similar to fields, except the contents of a zone can
      be arbitrary free text.
   5. Weighted zone scoring,
      (referred to also as ranked boolean retrieval)
   6. Machine-learned relevance,
   7. collection frequency, defined to be the total number of
      occurrences of a term in the collection.
   8. Document frequency dft , defined to be the number of documents
      in the collection that contain a term t.
   9. the vector space model is fundamental to a host of information
      retrieval operations ranging from scoring documents on a query,
      document classification and document clustering.
   10. cosine similarity
   11. TF(Term frequency Weights)
       The more often a term occurs in the text of the document d, the
       higher its term frequency weight TF is.
   12. Exhaustivity is a property of document desciptions
   13. specificity is a property of index terms. The specificity of an
       index term is interpreted as how well the term describes a
       dcument topic.
   15. Bayes Optimal decision Rule
       Optimal Decision Rule, the decision which minimizes the risk of
       loss, is to simply return documents that are more likely
       relevant than non-revelent:
       d is relevant iff P(R = 1| d, q) > P(R = 0| d, q)

* tf-idf(t, d)
  1. Maximum tf normalization:
     * A change in the stop word list can dramatically alter term
       weightings.
     * A document may contain an outlier term with an unusually large
       number of occurrences of that term, not representative of the
       content of that document.
     * More generally, a document in which the most frequent term
       appears roughly as often as many other terms should be treated
       differently from one with a more skewed distribution.
  2. Sublinear tf scaling.
     The main idea of maximum tf normalization is to mitigate the
     following anomaly
     - observe higher term frequencies in longer documents, merely
       because longer documents tend to repeat the same words over and
       over again.



* Pivoted document length documentation.
** Why use
   - First, longer documents will as a result of containing more terms have higher tf values.
   - Second, longer documents contain more distinct terms.
** when use
   - Make score skewed to account for the effect of document length on relevance.

* Binary Model

* Okapi BM25: a non-binary model
  BM25 weighting scheme.


* Bayesian network approaches to IR
  a form of probabilistic graphical model.

